{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science London Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定資料存放路徑\n",
    "data_path = '../data/data-science-london-scikit-learn/'\n",
    "\n",
    "# 讀入資料集\n",
    "train_data = pd.read_csv(data_path + 'train.csv',header = None)\n",
    "train_labels = pd.read_csv(data_path + 'trainLabels.csv',header = None)\n",
    "test_data =  pd.read_csv(data_path + 'test.csv',header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預覽訓練資料\n",
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 檢視資料維度\n",
    "train_data.shape, test_data.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 檢視訓練集統計量\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRE-PROCESSING 資料前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 資料分割\n",
    "x_train,x_test,y_train,y_test = train_test_split(train_data,train_labels, test_size = 0.30, random_state = 101)\n",
    "\n",
    "# 檢視資料維度\n",
    "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATION 分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAIBE BAYES\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(x_train,y_train.values.ravel())\n",
    "predicted= model.predict(x_test)\n",
    "print('Naive Bayes',accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(x_train,y_train.values.ravel())\n",
    "predicted= knn_model.predict(x_test)\n",
    "print('KNN',accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM FOREST\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_model = RandomForestClassifier(n_estimators = 100,random_state = 99)\n",
    "rfc_model.fit(x_train,y_train.values.ravel())\n",
    "predicted = rfc_model.predict(x_test)\n",
    "print('Random Forest',accuracy_score(y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOGISTIC REGRESSION\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(solver = 'saga')\n",
    "lr_model.fit(x_train,y_train.values.ravel())\n",
    "lr_predicted = lr_model.predict(x_test)\n",
    "print('Logistic Regression',accuracy_score(y_test, lr_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = SVC(gamma = 'auto')\n",
    "svc_model.fit(x_train,y_train.values.ravel())\n",
    "svc_predicted = svc_model.predict(x_test)\n",
    "print('SVM',accuracy_score(y_test, svc_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DECISON TREE\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_model = DecisionTreeClassifier()\n",
    "dtree_model.fit(x_train,y_train.values.ravel())\n",
    "dtree_predicted = dtree_model.predict(x_test)\n",
    "print('Decision Tree',accuracy_score(y_test, dtree_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBOOST\n",
    "'''\n",
    "from xgboost import XGBClassifier\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(x_train,y_train.values.ravel())\n",
    "xgb_predicted = xgb.predict(x_test)\n",
    "print('XGBoost',accuracy_score(y_test, xgb_predicted))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling 特徵縮放"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizer 標準化\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "\n",
    "norm = Normalizer()\n",
    "#x_norm_train = norm.fit_transform(x_train)\n",
    "#x_norm_test = norm.transform(x_test)\n",
    "norm_train_data = norm.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAIBE BAYES\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "#nb_model.fit(x_norm_train,y_train.values.ravel())\n",
    "#nb_predicted= nb_model.predict(x_norm_test)\n",
    "#print('Naive Bayes',accuracy_score(y_test, nb_predicted))\n",
    "print('Naive Bayes',cross_val_score(nb_model,norm_train_data, train_labels.values.ravel(), cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors = 5)\n",
    "#knn_model.fit(x_norm_train,y_train.values.ravel())\n",
    "#knn_predicted= knn_model.predict(x_norm_test)\n",
    "#print('KNN',accuracy_score(y_test, knn_predicted))\n",
    "print('KNN',cross_val_score(knn_model,norm_train_data, train_labels.values.ravel(), cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM FOREST\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc_model = RandomForestClassifier(n_estimators = 100,random_state = 99)\n",
    "#rfc_model.fit(x_norm_train,y_train.values.ravel())\n",
    "#rfc_predicted = rfc_model.predict(x_norm_test)\n",
    "#print('Random Forest',accuracy_score(y_test,rfc_predicted))\n",
    "print('Random Forest',cross_val_score(rfc_model,norm_train_data, train_labels.values.ravel(), cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOGISTIC REGRESSION\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression(solver = 'saga')\n",
    "#lr_model.fit(x_norm_train,y_train.values.ravel())\n",
    "#lr_predicted = lr_model.predict(x_norm_test)\n",
    "#print('Logistic Regression',accuracy_score(y_test, lr_predicted))\n",
    "print('Logistic Regression',cross_val_score(lr_model,norm_train_data, train_labels.values.ravel(), cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model = SVC(gamma = 'auto')\n",
    "#svc_model.fit(x_norm_train,y_train.values.ravel())\n",
    "#svc_predicted = svc_model.predict(x_norm_test)\n",
    "#print('SVM',accuracy_score(y_test, svc_predicted))\n",
    "print('SVM',cross_val_score(svc_model,norm_train_data, train_labels.values.ravel(), cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DECISON TREE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree_model = DecisionTreeClassifier()\n",
    "#dtree_model.fit(x_norm_train,y_train.values.ravel())\n",
    "#dtree_predicted = dtree_model.predict(x_norm_test)\n",
    "#print('Decision Tree',accuracy_score(y_test, dtree_predicted))\n",
    "print('Decision Tree',cross_val_score(dtree_model,norm_train_data, train_labels.values.ravel(), cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#XGBOOST\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "#xgb.fit(x_norm_train,y_train.values.ravel())\n",
    "#xgb_predicted = xgb.predict(x_norm_test)\n",
    "#print('XGBoost',accuracy_score(y_test, xgb_predicted))\n",
    "print('XGBoost',cross_val_score(xgb,norm_train_data, train_labels.values.ravel(), cv=10).mean())\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> KNN gave maximum accuracy using Feature Scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25054403 0.2055048  0.08026473 0.05033658 0.04895951 0.04489904\n",
      " 0.0417078  0.03127934 0.02309759 0.02100089 0.01618737 0.01267877]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca  = PCA(n_components=12)\n",
    "#x_train = pca.fit_transform(x_train)\n",
    "#x_test = pca.transform(x_test)\n",
    "pca_train_data = pca.fit_transform(train_data)\n",
    "explained_variance = pca.explained_variance_ratio_ \n",
    "print(explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 12)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes 0.841\n"
     ]
    }
   ],
   "source": [
    "# NAIBE BAYES\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "#nb_model.fit(pca_train_data,y_train.values.ravel())\n",
    "#nb_predicted= nb_model.predict(x_norm_test)\n",
    "#print('Naive Bayes',accuracy_score(y_test, nb_predicted))\n",
    "print('Naive Bayes',cross_val_score(nb_model,pca_train_data, train_labels.values.ravel(), cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 0.909\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors = 5)\n",
    "#knn_model.fit(pca_train_data,y_train.values.ravel())\n",
    "#knn_predicted= knn_model.predict(x_norm_test)\n",
    "#print('KNN',accuracy_score(y_test, knn_predicted))\n",
    "print('KNN',cross_val_score(knn_model,pca_train_data, train_labels.values.ravel(), cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest 0.908\n"
     ]
    }
   ],
   "source": [
    "#RANDOM FOREST\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc_model = RandomForestClassifier(n_estimators = 100,random_state = 99)\n",
    "#rfc_model.fit(pca_train_data,y_train.values.ravel())\n",
    "#rfc_predicted = rfc_model.predict(x_norm_test)\n",
    "#print('Random Forest',accuracy_score(y_test,rfc_predicted))\n",
    "print('Random Forest',cross_val_score(rfc_model,pca_train_data, train_labels.values.ravel(), cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest 0.908\n"
     ]
    }
   ],
   "source": [
    "#RANDOM FOREST\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc_model = RandomForestClassifier(n_estimators = 100,random_state = 99)\n",
    "#rfc_model.fit(pca_train_data,y_train.values.ravel())\n",
    "#rfc_predicted = rfc_model.predict(x_norm_test)\n",
    "#print('Random Forest',accuracy_score(y_test,rfc_predicted))\n",
    "print('Random Forest',cross_val_score(rfc_model,pca_train_data, train_labels.values.ravel(), cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM 0.905\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model = SVC(gamma = 'auto')\n",
    "#svc_model.fit(x_norm_train,y_train.values.ravel())\n",
    "#svc_predicted = svc_model.predict(x_norm_test)\n",
    "#print('SVM',accuracy_score(y_test, svc_predicted))\n",
    "print('SVM',cross_val_score(svc_model,pca_train_data, train_labels.values.ravel(), cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree 0.8099999999999999\n"
     ]
    }
   ],
   "source": [
    "#DECISON TREE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree_model = DecisionTreeClassifier()\n",
    "#dtree_model.fit(x_norm_train,y_train.values.ravel())\n",
    "#dtree_predicted = dtree_model.predict(x_norm_test)\n",
    "#print('Decision Tree',accuracy_score(y_test, dtree_predicted))\n",
    "print('Decision Tree',cross_val_score(dtree_model,pca_train_data, train_labels.values.ravel(), cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#XGBOOST\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "#xgb.fit(x_norm_train,y_train.values.ravel())\n",
    "#xgb_predicted = xgb.predict(x_norm_test)\n",
    "#print('XGBoost',accuracy_score(y_test, xgb_predicted))\n",
    "print('XGBoost',cross_val_score(xgb,pca_train_data, train_labels.values.ravel(), cv=10).mean())\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> KNN, Random Forest and SVM gave maximum accuracy using Principal Component Analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Gaussian Mixture and Grid Search to improve the accuracy\n",
    "\n",
    "We select the above three algorithms (KNN, Random Forest and SVM) which gave maximum accuracy for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_all shape : (10000, 40)\n"
     ]
    }
   ],
   "source": [
    "x_all = np.r_[train_data,test_data]\n",
    "print('x_all shape :',x_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USING THE GAUSSIAN MIXTURE MODEL \n",
    "lowest_bic = np.infty\n",
    "bic = []\n",
    "n_components_range = range(1, 7)\n",
    "cv_types = ['spherical', 'tied', 'diag', 'full']\n",
    "\n",
    "for cv_type in cv_types:\n",
    "    for n_components in n_components_range:\n",
    "        gmm = GaussianMixture(n_components=n_components,covariance_type=cv_type)\n",
    "        gmm.fit(x_all)\n",
    "        bic.append(gmm.aic(x_all))\n",
    "        if bic[-1] < lowest_bic:\n",
    "            lowest_bic = bic[-1]\n",
    "            best_gmm = gmm\n",
    "            \n",
    "\n",
    "best_gmm.fit(x_all)\n",
    "gmm_train = best_gmm.predict_proba(train_data)\n",
    "gmm_test = best_gmm.predict_proba(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Classifier\n",
    "rfc = RandomForestClassifier(random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Best Score 0.996\n",
      "Random Forest Best Parmas {'max_depth': 3, 'n_estimators': 10}\n",
      "Random Forest Accuracy 0.9960000000000001\n"
     ]
    }
   ],
   "source": [
    "#USING GRID SEARCH\n",
    "n_estimators = [10, 50, 100, 200,400]\n",
    "max_depth = [3, 10, 20, 40]\n",
    "param_grid = dict(n_estimators=n_estimators,max_depth=max_depth)\n",
    "\n",
    "grid_search_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv = 10,scoring='accuracy',n_jobs=-1).fit(gmm_train, train_labels.values.ravel())\n",
    "rfc_best = grid_search_rfc.best_estimator_\n",
    "\n",
    "print('Random Forest Best Score',grid_search_rfc.best_score_)\n",
    "print('Random Forest Best Parmas',grid_search_rfc.best_params_)\n",
    "print('Random Forest Accuracy',cross_val_score(rfc_best,gmm_train, train_labels.values.ravel(), cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Best Score 0.996\n",
      "KNN Best Params {'n_neighbors': 3}\n",
      "KNN Accuracy 0.9960000000000001\n"
     ]
    }
   ],
   "source": [
    "#KNN \n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "#USING GRID SEARCH\n",
    "n_neighbors=[3,5,6,7,8,9,10]\n",
    "param_grid = dict(n_neighbors=n_neighbors)\n",
    "\n",
    "grid_search_knn = GridSearchCV(estimator=knn, param_grid=param_grid, \n",
    "                               cv = 10, n_jobs=-1,\n",
    "                               scoring='accuracy').fit(gmm_train,train_labels.values.ravel())\n",
    "knn_best = grid_search_knn.best_estimator_\n",
    "\n",
    "print('KNN Best Score', grid_search_knn.best_score_)\n",
    "print('KNN Best Params',grid_search_knn.best_params_)\n",
    "print('KNN Accuracy',cross_val_score(knn_best,gmm_train, train_labels.values.ravel(), cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Best Score 0.996\n",
      "SVM Best Params {'C': 1, 'kernel': 'linear'}\n",
      "SVM Accuracy 0.9960000000000001\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "svc = SVC()\n",
    "\n",
    "#USING GRID SEARCH\n",
    "parameters = [{'kernel':['linear'],'C':[1,10,100]},\n",
    "              {'kernel':['rbf'],'C':[1,10,100],'gamma':[0.05,0.0001,0.01,0.001]}]\n",
    "\n",
    "grid_search_svm = GridSearchCV(estimator=svc, param_grid=parameters, \n",
    "                               cv = 10, n_jobs=-1,\n",
    "                               scoring='accuracy').fit(gmm_train, train_labels.values.ravel())\n",
    "svm_best = grid_search_svm.best_estimator_\n",
    "\n",
    "print('SVM Best Score',grid_search_svm.best_score_)\n",
    "print('SVM Best Params',grid_search_svm.best_params_)\n",
    "print('SVM Accuracy',cross_val_score(svm_best,gmm_train, train_labels.values.ravel(), cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_best.fit(gmm_train,train_labels.values.ravel())\n",
    "pred  = rfc_best.predict(gmm_test)\n",
    "rfc_best_pred = pd.DataFrame(pred)\n",
    "\n",
    "rfc_best_pred.index += 1\n",
    "\n",
    "rfc_best_pred.columns = ['Solution']\n",
    "rfc_best_pred['Id'] = np.arange(1,rfc_best_pred.shape[0]+1)\n",
    "rfc_best_pred = rfc_best_pred[['Id', 'Solution']]\n",
    "\n",
    "rfc_best_pred.to_csv('Day_048_Submission_GMM_RFC_V2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
